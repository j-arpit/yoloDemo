{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524e0025-1ba5-4840-b70e-57eb3042b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for MLflow Tracking\n",
    "ExpName = \"mlflowtemplate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae75df1-01b5-4da4-825d-95cb1d765f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96abde5-1d98-438c-a3cf-e36231eefd19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54f84ff-36b3-418e-9722-f9ac6cca9829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b93aaf8-e329-481d-9235-71a44eddc9de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4937478e-4a64-4ff4-9cda-fff252e9a1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "082dc697-a044-4f6e-a0db-92044767e4fa",
   "metadata": {},
   "source": [
    "### Mlflow Logging Section\n",
    "###### Add all the params and metrics here which you have used to train the Model here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eea463-8f61-41b9-9c4e-a3e7ae931fd0",
   "metadata": {
    "tags": []
   },
   "source": [
    "###### This is the start_run block make sure to save the code, commit it to the Git. The commit id will attached to this run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffc09eb-98d6-4c9c-b628-a465f2ae8198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import git \n",
    "\n",
    "mlflow.set_experiment(ExpName)\n",
    "\n",
    "repo = git.Repo(\"\")\n",
    "with mlflow.start_run():\n",
    "    # Log the parameters used for the model fit\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log the error metrics that were calculated during validation\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    tag = {MLFLOW_GIT_COMMIT: repo.head.commit, MLFLOW_SOURCE_TYPE:'GIT PROJECT', \n",
    "           MLFLOW_GIT_BRANCH:repo.active_branch, MLFLOW_SOURCE_NAME:repo.remote().url}\n",
    "\n",
    "    mlflow.set_tags(tag)\n",
    "    # Each Branch corresponds to one Registered Model in mlflow\n",
    "    model_name = repo.active_branch.name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a49986-d512-49f1-981f-daa235742117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
